---
title: "DengAI: Predicting Disease Spread Submission"
author: "Phil Jauregui"
date: "`r Sys.Date()`"
output: html_document
---

# 1. Load Packages
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(tsibble)
library(stats)
library(forecast)
```

# 2. Read in Data
```{r}
train_labels <- read_csv("C:/Users/jaure/Downloads/dengue_labels_train.csv", show_col_types = FALSE)

train_features <- read_csv("C:/Users/jaure/Downloads/dengue_features_train.csv",show_col_types = FALSE)

test_features <- read_csv("C:/Users/jaure/Downloads/dengue_features_test.csv",show_col_types = FALSE)

submissions <- read_csv("C:/Users/jaure/Downloads/submission_format.csv",show_col_types = FALSE)
```

# 3. Tidy Data
```{r}
# Bind training data
train <- left_join(x=train_labels, y=train_features, by=c("year", "weekofyear", "city"))

# Omit NA values from the training set
train <- na.omit(train)
```
Filter data by city

```{r}
# San Juan
sj <- train %>% filter(city=="sj")
# Iquitos 
iq <- train %>% filter(city=="iq")
```

Create a time series for each city
```{r}
sjTS <- ts(sj$total_cases, start=c(1))
iqTS <- ts(iq$total_cases, start=c(1))
```

# 4. Plot Dengue Cases Over Time

```{r}
# Plot Total Dengue Cases
ggplot(sj, aes(x = week_start_date, y = total_cases)) +
    geom_line() +
    labs(x = "Date", y = "Total Cases", title = "Total Dengue Cases in San Juan")

ggplot(iq, aes(x = week_start_date, y = total_cases)) +
    geom_line() +
    labs(x = "Date", y = "Total Cases", title = "Total Dengue Cases in Iquitos")

combined_data <- rbind(
    mutate(sj, city = "San Juan"),
    mutate(iq, city = "Iquitos")
)

ggplot(combined_data, aes(x = week_start_date, y = total_cases, color = city)) +
    geom_line() +
    labs(x = "Date", y = "Total Cases", title = "Total Dengue Cases in San Juan and Iquitos")
```

# 5. Create forecasting models
(Seasonal Naive, ETS, ARIMA, Dynamic Regression)

## Model 1: ETS 
### San Juan
```{r}
# San Juan
sj_ets <- ets(sjTS)

forecast(sj_ets, h=52)
sjf1 <- forecast(sj_ets, h=52)
autoplot(sjf1) + xlab("Week") + ylab("Total Cases of Dengue Fever") + ggtitle("Forecast of Total Dengue Cases in San Juan (ETS)")
```

```{r}
checkresiduals(sjf1)
```

### Iquitos
```{r}
iq_ets <- ets(iqTS)

forecast(iq_ets, h=52)
iqf1 <- forecast(iq_ets, h=52)
autoplot(iqf1) + xlab("Week") + ylab("Total Cases of Dengue Fever") + ggtitle("Forecast of Total Dengue Cases in Iquitos (ETS)")
```

```{r}
checkresiduals(iqf1)
```


## Model 2: ARIMA

### San Juan
```{r}
## San Juan
sj_ARIMA <- auto.arima(sjTS)

sjf2 <- forecast(sj_ARIMA, h=52)
autoplot(sjf2) + xlab("Week") + ylab("Total Cases of Dengue Fever") + ggtitle("Forecast of Total Dengue Cases in San Juan (ARIMA)")

```

```{r}
checkresiduals(sjf2)
```

### Iquitos

```{r}
iq_ARIMA <- auto.arima(iqTS)

iqf2 <- forecast(iq_ARIMA, h=52)
autoplot(iqf2) + xlab("Week") + ylab("Total Cases of Dengue Fever") + ggtitle("Forecast of Total Dengue Cases in Iquitos (ARIMA)")
```

```{r}
checkresiduals(iqf2)
```


## Model 3: Neural Network Model (nnetar)

### San Juan
```{r}
sj_total_cases <- ts(sj$total_cases, frequency = 52, start = c(1990, 04, 30))
sj_nnetar <- nnetar(sj_total_cases, repeats = 25, size = 12, decay = 0.1, linout = TRUE)

plot(forecast(sj_nnetar, h = 260), main = "Total Dengue Cases (San Juan)", xlab = "Year", ylab = "Total Cases")
```

### Iquitos
```{r}
iq_total_cases <- ts(iq$total_cases, frequency = 52, start = c(2000, 07, 01))

iq_nnetar <- nnetar(iq_total_cases, repeats = 25, size = 18, decay = 0.1, linout = TRUE)
plot(forecast(iq_nnetar, h = 156), main = "Total Dengue Cases (Iquitos)", xlab = "Weeks", ylab = "Total Cases")
```

## Proposed Model: Dynamic Regression

If I were to build a dynamic regression model, I would want to first select variables as extermal regressors.
To select variables as external regressors, I want to examine the correlations of the feature variables with the number of total cases.

## Examine Correlations
```{r}
# construct a correlation matrix
m_sj_train_features <- data.matrix(sj)
m_sj_train_features <- cor(x = m_sj_train_features, use = 'complete.obs', method = 'pearson')

m_iq_train_features <- data.matrix(iq)
m_iq_train_features <- cor(x = m_iq_train_features, use = 'everything', method = 'pearson')
```

```{r}
#Convert matrix into a dataframe of correlation coefficients
df_sj_train_features <- data.frame(m_sj_train_features)[2:21,] 
df_sj_train_features <- dplyr::select(df_sj_train_features, total_cases) 
                                    
df_iq_train_features <- data.frame(m_iq_train_features)[2:21,]
df_iq_train_features <- dplyr::select(df_iq_train_features, total_cases) 
```

### Plot the correlation coefficients
```{r}
ggplot(df_sj_train_features, aes(x = reorder(rownames(df_sj_train_features), -total_cases), y = total_cases, fill = abs(total_cases))) +
  geom_bar(stat = 'identity') +
  theme_bw() +
  scale_fill_gradient(low = "blue", high = "red") +
  ggtitle('Correlation of variables with Total Cases (SJ)') +
  ylab('Correlation Coefficient (r)') +
  xlab('Variables') +
  coord_flip()
```

```{r}
ggplot(df_iq_train_features, aes(x = reorder(rownames(df_iq_train_features), -total_cases), y = total_cases, fill = abs(total_cases))) +
  geom_bar(stat = 'identity') +
  theme_bw() +
  scale_fill_gradient(low = "blue", high = "red") +
  ggtitle('Correlation of variables with Total Cases (IQ)') +
  ylab('Correlation Coefficient (r)') +
  xlab('Variables') +
  coord_flip()
```

Interested in those variables that have r >= .2 in both cities, I would select:
reanalysis_specific_humidity_g_per_kg 
and 
reanalysis_dew_point_temp_k as external regressors.
as external regressors in a dynamic regression model.

# 6. Evaluate the Models

## ETS 

### San Juan
```{r}
summary(sj_ets)
```
### Iquitos
```{r}
summary(iq_ets)
```
## ARIMA 

### ARIMA
```{r}
summary(sj_ARIMA)
```
### Iquitos
```{r}
summary(iq_ARIMA)
```

## Neural Net 
### San Jose
```{r}
accuracy(sj_nnetar)
```

### Iquitos
```{r}
accuracy(iq_nnetar)
```


## 7. Generate the submission

Examining accuracy metrics for the models, we see that the neural network models outperformed the other models, displaying the lowest RMSE and MAE values (8.7 and 6.1 for San Juan and 3.36 and 2.44 for Iquitos).

Accordingly, I moved forward with the neural network model and used that forecasting model as my submission to DrivenData @ https://www.drivendata.org/competitions/44/dengai-predicting-disease-spread/page/80/ 

```{r}
a <- forecast(sj_nnetar, h = 260)
sj_nnetar_solution <- data.frame(submissions[1:260, -4], total_cases = round(a$mean))

b <- forecast(iq_nnetar, h = 156)
iq_nnetar_solution <- data.frame(submissions[261:416, -4], total_cases = round(b$mean))

nnetar_solution <- bind_rows(sj_nnetar_solution, iq_nnetar_solution)

write.csv(nnetar_solution, file = 'DengAI_nnetar_predicted_solution.csv', row.names = FALSE)
```
